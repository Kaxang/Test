{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第5章 决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1．分类决策树模型是表示基于特征对实例进行分类的树形结构。决策树可以转换成一个**if-then**规则的集合，也可以看作是定义在特征空间划分上的类的条件概率分布。\n",
    "\n",
    "2．决策树学习旨在构建一个与训练数据拟合很好，并且复杂度小的决策树。因为从可能的决策树中直接选取最优决策树是NP完全问题。现实中采用启发式方法学习次优的决策树。\n",
    "\n",
    "决策树学习算法包括3部分：特征选择、树的生成和树的剪枝。常用的算法有ID3、\n",
    "C4.5和CART。\n",
    "\n",
    "3．特征选择的目的在于选取对训练数据能够分类的特征。特征选择的关键是其准则。常用的准则如下：\n",
    "\n",
    "（1）样本集合$D$对特征$A$的信息增益（ID3）\n",
    "\n",
    "\n",
    "$$g(D, A)=H(D)-H(D|A)$$\n",
    "\n",
    "$$H(D)=-\\sum_{k=1}^{K} \\frac{\\left|C_{k}\\right|}{|D|} \\log _{2} \\frac{\\left|C_{k}\\right|}{|D|}$$\n",
    "\n",
    "$$H(D | A)=\\sum_{i=1}^{n} \\frac{\\left|D_{i}\\right|}{|D|} H\\left(D_{i}\\right)$$\n",
    "\n",
    "其中，$H(D)$是数据集$D$的熵，$H(D_i)$是数据集$D_i$的熵，$H(D|A)$是数据集$D$对特征$A$的条件熵。\t$D_i$是$D$中特征$A$取第$i$个值的样本子集，$C_k$是$D$中属于第$k$类的样本子集。$n$是特征$A$取 值的个数，$K$是类的个数。\n",
    "\n",
    "（2）样本集合$D$对特征$A$的信息增益比（C4.5）\n",
    "\n",
    "\n",
    "$$g_{R}(D, A)=\\frac{g(D, A)}{H(D)}$$\n",
    "\n",
    "\n",
    "其中，$g(D,A)$是信息增益，$H(D)$是数据集$D$的熵。\n",
    "\n",
    "（3）样本集合$D$的基尼指数（CART）\n",
    "\n",
    "$$\\operatorname{Gini}(D)=1-\\sum_{k=1}^{K}\\left(\\frac{\\left|C_{k}\\right|}{|D|}\\right)^{2}$$\n",
    "\n",
    "特征$A$条件下集合$D$的基尼指数：\n",
    "\n",
    " $$\\operatorname{Gini}(D, A)=\\frac{\\left|D_{1}\\right|}{|D|} \\operatorname{Gini}\\left(D_{1}\\right)+\\frac{\\left|D_{2}\\right|}{|D|} \\operatorname{Gini}\\left(D_{2}\\right)$$\n",
    " \n",
    "4．决策树的生成。通常使用信息增益最大、信息增益比最大或基尼指数最小作为特征选择的准则。决策树的生成往往通过计算信息增益或其他指标，从根结点开始，递归地产生决策树。这相当于用信息增益或其他准则不断地选取局部最优的特征，或将训练集分割为能够基本正确分类的子集。\n",
    "\n",
    "5．决策树的剪枝。由于生成的决策树存在过拟合问题，需要对它进行剪枝，以简化学到的决策树。决策树的剪枝，往往从已生成的树上剪掉一些叶结点或叶结点以上的子树，并将其父结点或根结点作为新的叶结点，从而简化生成的决策树。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import math\n",
    "from math import log\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 书上题目5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 书上题目5.1\n",
    "def create_data():\n",
    "    datasets = [['青年', '否', '否', '一般', '否'],\n",
    "               ['青年', '否', '否', '好', '否'],\n",
    "               ['青年', '是', '否', '好', '是'],\n",
    "               ['青年', '是', '是', '一般', '是'],\n",
    "               ['青年', '否', '否', '一般', '否'],\n",
    "               ['中年', '否', '否', '一般', '否'],\n",
    "               ['中年', '否', '否', '好', '否'],\n",
    "               ['中年', '是', '是', '好', '是'],\n",
    "               ['中年', '否', '是', '非常好', '是'],\n",
    "               ['中年', '否', '是', '非常好', '是'],\n",
    "               ['老年', '否', '是', '非常好', '是'],\n",
    "               ['老年', '否', '是', '好', '是'],\n",
    "               ['老年', '是', '否', '好', '是'],\n",
    "               ['老年', '是', '否', '非常好', '是'],\n",
    "               ['老年', '否', '否', '一般', '否'],\n",
    "               ]\n",
    "    labels = [u'年龄', u'有工作', u'有自己的房子', u'信贷情况', u'类别']\n",
    "    # 返回数据集和每个维度的名称\n",
    "    return datasets, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets, labels = create_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(datasets, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>年龄</th>\n",
       "      <th>有工作</th>\n",
       "      <th>有自己的房子</th>\n",
       "      <th>信贷情况</th>\n",
       "      <th>类别</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>青年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>一般</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>青年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>好</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>青年</td>\n",
       "      <td>是</td>\n",
       "      <td>否</td>\n",
       "      <td>好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>青年</td>\n",
       "      <td>是</td>\n",
       "      <td>是</td>\n",
       "      <td>一般</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>青年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>一般</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>中年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>一般</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>中年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>好</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>中年</td>\n",
       "      <td>是</td>\n",
       "      <td>是</td>\n",
       "      <td>好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>中年</td>\n",
       "      <td>否</td>\n",
       "      <td>是</td>\n",
       "      <td>非常好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>中年</td>\n",
       "      <td>否</td>\n",
       "      <td>是</td>\n",
       "      <td>非常好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>老年</td>\n",
       "      <td>否</td>\n",
       "      <td>是</td>\n",
       "      <td>非常好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>老年</td>\n",
       "      <td>否</td>\n",
       "      <td>是</td>\n",
       "      <td>好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>老年</td>\n",
       "      <td>是</td>\n",
       "      <td>否</td>\n",
       "      <td>好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>老年</td>\n",
       "      <td>是</td>\n",
       "      <td>否</td>\n",
       "      <td>非常好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>老年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>一般</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    年龄 有工作 有自己的房子 信贷情况 类别\n",
       "0   青年   否      否   一般  否\n",
       "1   青年   否      否    好  否\n",
       "2   青年   是      否    好  是\n",
       "3   青年   是      是   一般  是\n",
       "4   青年   否      否   一般  否\n",
       "5   中年   否      否   一般  否\n",
       "6   中年   否      否    好  否\n",
       "7   中年   是      是    好  是\n",
       "8   中年   否      是  非常好  是\n",
       "9   中年   否      是  非常好  是\n",
       "10  老年   否      是  非常好  是\n",
       "11  老年   否      是    好  是\n",
       "12  老年   是      否    好  是\n",
       "13  老年   是      否  非常好  是\n",
       "14  老年   否      否   一般  否"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 熵\n",
    "def calc_ent(datasets):\n",
    "    data_length = len(datasets)\n",
    "    label_count = {}\n",
    "    for i in range(data_length):\n",
    "        label = datasets[i][-1]\n",
    "        if label not in label_count:\n",
    "            label_count[label] = 0\n",
    "        label_count[label] += 1\n",
    "    ent = -sum([(p / data_length) * log(p / data_length, 2)\n",
    "                for p in label_count.values()])\n",
    "    return ent\n",
    "# def entropy(y):\n",
    "#     \"\"\"\n",
    "#     Entropy of a label sequence\n",
    "#     \"\"\"\n",
    "#     hist = np.bincount(y)\n",
    "#     ps = hist / np.sum(hist)\n",
    "#     return -np.sum([p * np.log2(p) for p in ps if p > 0])\n",
    "\n",
    "\n",
    "# 经验条件熵\n",
    "def cond_ent(datasets, axis=0):\n",
    "    data_length = len(datasets)\n",
    "    feature_sets = {}\n",
    "    for i in range(data_length):\n",
    "        feature = datasets[i][axis]\n",
    "        if feature not in feature_sets:\n",
    "            feature_sets[feature] = []\n",
    "        feature_sets[feature].append(datasets[i])\n",
    "    cond_ent = sum(\n",
    "        [(len(p) / data_length) * calc_ent(p) for p in feature_sets.values()])\n",
    "    return cond_ent\n",
    "\n",
    "\n",
    "# 信息增益\n",
    "def info_gain(ent, cond_ent):\n",
    "    return ent - cond_ent\n",
    "\n",
    "\n",
    "def info_gain_train(datasets):\n",
    "    count = len(datasets[0]) - 1\n",
    "    ent = calc_ent(datasets)\n",
    "#     ent = entropy(datasets)\n",
    "    best_feature = []\n",
    "    for c in range(count):\n",
    "        c_info_gain = info_gain(ent, cond_ent(datasets, axis=c))\n",
    "        best_feature.append((c, c_info_gain))\n",
    "        print('特征({}) - info_gain - {:.3f}'.format(labels[c], c_info_gain))\n",
    "    # 比较大小\n",
    "    best_ = max(best_feature, key=lambda x: x[-1])\n",
    "    return '特征({})的信息增益最大，选择为根节点特征'.format(labels[best_[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征(年龄) - info_gain - 0.083\n",
      "特征(有工作) - info_gain - 0.324\n",
      "特征(有自己的房子) - info_gain - 0.420\n",
      "特征(信贷情况) - info_gain - 0.363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'特征(有自己的房子)的信息增益最大，选择为根节点特征'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_gain_train(np.array(datasets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "利用ID3算法生成决策树，例5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义节点类 二叉树\n",
    "class Node:\n",
    "    def __init__(self, root=True, label=None, feature_name=None, feature=None):\n",
    "        self.root = root\n",
    "        self.label = label\n",
    "        self.feature_name = feature_name\n",
    "        self.feature = feature\n",
    "        self.tree = {}\n",
    "        self.result = {\n",
    "            'label:': self.label,\n",
    "            'feature': self.feature,\n",
    "            'tree': self.tree\n",
    "        }\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}'.format(self.result)\n",
    "\n",
    "    def add_node(self, val, node):\n",
    "        self.tree[val] = node\n",
    "\n",
    "    def predict(self, features):\n",
    "        if self.root is True:\n",
    "            return self.label\n",
    "        return self.tree[features[self.feature]].predict(features)\n",
    "\n",
    "\n",
    "class DTree:\n",
    "    def __init__(self, epsilon=0.1):\n",
    "        self.epsilon = epsilon\n",
    "        self._tree = {}\n",
    "\n",
    "    # 熵\n",
    "    @staticmethod\n",
    "    def calc_ent(datasets):\n",
    "        data_length = len(datasets)\n",
    "        label_count = {}\n",
    "        for i in range(data_length):\n",
    "            label = datasets[i][-1]\n",
    "            if label not in label_count:\n",
    "                label_count[label] = 0\n",
    "            label_count[label] += 1\n",
    "        ent = -sum([(p / data_length) * log(p / data_length, 2)\n",
    "                    for p in label_count.values()])\n",
    "        return ent\n",
    "\n",
    "    # 经验条件熵\n",
    "    def cond_ent(self, datasets, axis=0):\n",
    "        data_length = len(datasets)\n",
    "        feature_sets = {}\n",
    "        for i in range(data_length):\n",
    "            feature = datasets[i][axis]\n",
    "            if feature not in feature_sets:\n",
    "                feature_sets[feature] = []\n",
    "            feature_sets[feature].append(datasets[i])\n",
    "        cond_ent = sum([(len(p) / data_length) * self.calc_ent(p)\n",
    "                        for p in feature_sets.values()])\n",
    "        return cond_ent\n",
    "\n",
    "    # 信息增益\n",
    "    @staticmethod\n",
    "    def info_gain(ent, cond_ent):\n",
    "        return ent - cond_ent\n",
    "\n",
    "    def info_gain_train(self, datasets):\n",
    "        count = len(datasets[0]) - 1\n",
    "        ent = self.calc_ent(datasets)\n",
    "        best_feature = []\n",
    "        for c in range(count):\n",
    "            c_info_gain = self.info_gain(ent, self.cond_ent(datasets, axis=c))\n",
    "            best_feature.append((c, c_info_gain))\n",
    "        # 比较大小\n",
    "        best_ = max(best_feature, key=lambda x: x[-1])\n",
    "        return best_\n",
    "\n",
    "    def train(self, train_data):\n",
    "        \"\"\"\n",
    "        input:数据集D(DataFrame格式)，特征集A，阈值eta\n",
    "        output:决策树T\n",
    "        \"\"\"\n",
    "        _, y_train, features = train_data.iloc[:, :\n",
    "                                               -1], train_data.iloc[:,\n",
    "                                                                    -1], train_data.columns[:\n",
    "                                                                                            -1]\n",
    "        # 1,若D中实例属于同一类Ck，则T为单节点树，并将类Ck作为结点的类标记，返回T\n",
    "        if len(y_train.value_counts()) == 1:\n",
    "            return Node(root=True, label=y_train.iloc[0])\n",
    "\n",
    "        # 2, 若A为空，则T为单节点树，将D中实例树最大的类Ck作为该节点的类标记，返回T\n",
    "        if len(features) == 0:\n",
    "            return Node(\n",
    "                root=True,\n",
    "                label=y_train.value_counts().sort_values(\n",
    "                    ascending=False).index[0])\n",
    "\n",
    "        # 3,计算最大信息增益 同5.1,Ag为信息增益最大的特征\n",
    "        max_feature, max_info_gain = self.info_gain_train(np.array(train_data))\n",
    "        max_feature_name = features[max_feature]\n",
    "\n",
    "        # 4,Ag的信息增益小于阈值eta,则置T为单节点树，并将D中是实例数最大的类Ck作为该节点的类标记，返回T\n",
    "        if max_info_gain < self.epsilon:\n",
    "            return Node(\n",
    "                root=True,\n",
    "                label=y_train.value_counts().sort_values(\n",
    "                    ascending=False).index[0])\n",
    "\n",
    "        # 5,构建Ag子集\n",
    "        node_tree = Node(\n",
    "            root=False, feature_name=max_feature_name, feature=max_feature)\n",
    "\n",
    "        feature_list = train_data[max_feature_name].value_counts().index\n",
    "        for f in feature_list:\n",
    "            sub_train_df = train_data.loc[train_data[max_feature_name] ==\n",
    "                                          f].drop([max_feature_name], axis=1)\n",
    "\n",
    "            # 6, 递归生成树\n",
    "            sub_tree = self.train(sub_train_df)\n",
    "            node_tree.add_node(f, sub_tree)\n",
    "\n",
    "        # pprint.pprint(node_tree.tree)\n",
    "        return node_tree\n",
    "\n",
    "    def fit(self, train_data):\n",
    "        self._tree = self.train(train_data)\n",
    "        return self._tree\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        return self._tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets, labels = create_data()\n",
    "data_df = pd.DataFrame(datasets, columns=labels)\n",
    "dt = DTree()\n",
    "tree = dt.fit(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label:': None, 'feature': 2, 'tree': {'否': {'label:': None, 'feature': 1, 'tree': {'否': {'label:': '否', 'feature': None, 'tree': {}}, '是': {'label:': '是', 'feature': None, 'tree': {}}}}, '是': {'label:': '是', 'feature': None, 'tree': {}}}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'否'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.predict(['老年', '否', '否', '一般'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "def create_data():\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['label'] = iris.target\n",
    "    df.columns = [\n",
    "        'sepal length', 'sepal width', 'petal length', 'petal width', 'label'\n",
    "    ]\n",
    "    \n",
    "    #取前100条数据：前2个class+label\n",
    "    data = np.array(df.iloc[:100, [0, 1, -1]])\n",
    "    \n",
    "    return data[:, :2], data[:, -1]\n",
    "    \n",
    "\n",
    "\n",
    "X, y = create_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
      "       [4.9, 3. , 1.4, 0.2],\n",
      "       [4.7, 3.2, 1.3, 0.2],\n",
      "       [4.6, 3.1, 1.5, 0.2],\n",
      "       [5. , 3.6, 1.4, 0.2],\n",
      "       [5.4, 3.9, 1.7, 0.4],\n",
      "       [4.6, 3.4, 1.4, 0.3],\n",
      "       [5. , 3.4, 1.5, 0.2],\n",
      "       [4.4, 2.9, 1.4, 0.2],\n",
      "       [4.9, 3.1, 1.5, 0.1],\n",
      "       [5.4, 3.7, 1.5, 0.2],\n",
      "       [4.8, 3.4, 1.6, 0.2],\n",
      "       [4.8, 3. , 1.4, 0.1],\n",
      "       [4.3, 3. , 1.1, 0.1],\n",
      "       [5.8, 4. , 1.2, 0.2],\n",
      "       [5.7, 4.4, 1.5, 0.4],\n",
      "       [5.4, 3.9, 1.3, 0.4],\n",
      "       [5.1, 3.5, 1.4, 0.3],\n",
      "       [5.7, 3.8, 1.7, 0.3],\n",
      "       [5.1, 3.8, 1.5, 0.3],\n",
      "       [5.4, 3.4, 1.7, 0.2],\n",
      "       [5.1, 3.7, 1.5, 0.4],\n",
      "       [4.6, 3.6, 1. , 0.2],\n",
      "       [5.1, 3.3, 1.7, 0.5],\n",
      "       [4.8, 3.4, 1.9, 0.2],\n",
      "       [5. , 3. , 1.6, 0.2],\n",
      "       [5. , 3.4, 1.6, 0.4],\n",
      "       [5.2, 3.5, 1.5, 0.2],\n",
      "       [5.2, 3.4, 1.4, 0.2],\n",
      "       [4.7, 3.2, 1.6, 0.2],\n",
      "       [4.8, 3.1, 1.6, 0.2],\n",
      "       [5.4, 3.4, 1.5, 0.4],\n",
      "       [5.2, 4.1, 1.5, 0.1],\n",
      "       [5.5, 4.2, 1.4, 0.2],\n",
      "       [4.9, 3.1, 1.5, 0.2],\n",
      "       [5. , 3.2, 1.2, 0.2],\n",
      "       [5.5, 3.5, 1.3, 0.2],\n",
      "       [4.9, 3.6, 1.4, 0.1],\n",
      "       [4.4, 3. , 1.3, 0.2],\n",
      "       [5.1, 3.4, 1.5, 0.2],\n",
      "       [5. , 3.5, 1.3, 0.3],\n",
      "       [4.5, 2.3, 1.3, 0.3],\n",
      "       [4.4, 3.2, 1.3, 0.2],\n",
      "       [5. , 3.5, 1.6, 0.6],\n",
      "       [5.1, 3.8, 1.9, 0.4],\n",
      "       [4.8, 3. , 1.4, 0.3],\n",
      "       [5.1, 3.8, 1.6, 0.2],\n",
      "       [4.6, 3.2, 1.4, 0.2],\n",
      "       [5.3, 3.7, 1.5, 0.2],\n",
      "       [5. , 3.3, 1.4, 0.2],\n",
      "       [7. , 3.2, 4.7, 1.4],\n",
      "       [6.4, 3.2, 4.5, 1.5],\n",
      "       [6.9, 3.1, 4.9, 1.5],\n",
      "       [5.5, 2.3, 4. , 1.3],\n",
      "       [6.5, 2.8, 4.6, 1.5],\n",
      "       [5.7, 2.8, 4.5, 1.3],\n",
      "       [6.3, 3.3, 4.7, 1.6],\n",
      "       [4.9, 2.4, 3.3, 1. ],\n",
      "       [6.6, 2.9, 4.6, 1.3],\n",
      "       [5.2, 2.7, 3.9, 1.4],\n",
      "       [5. , 2. , 3.5, 1. ],\n",
      "       [5.9, 3. , 4.2, 1.5],\n",
      "       [6. , 2.2, 4. , 1. ],\n",
      "       [6.1, 2.9, 4.7, 1.4],\n",
      "       [5.6, 2.9, 3.6, 1.3],\n",
      "       [6.7, 3.1, 4.4, 1.4],\n",
      "       [5.6, 3. , 4.5, 1.5],\n",
      "       [5.8, 2.7, 4.1, 1. ],\n",
      "       [6.2, 2.2, 4.5, 1.5],\n",
      "       [5.6, 2.5, 3.9, 1.1],\n",
      "       [5.9, 3.2, 4.8, 1.8],\n",
      "       [6.1, 2.8, 4. , 1.3],\n",
      "       [6.3, 2.5, 4.9, 1.5],\n",
      "       [6.1, 2.8, 4.7, 1.2],\n",
      "       [6.4, 2.9, 4.3, 1.3],\n",
      "       [6.6, 3. , 4.4, 1.4],\n",
      "       [6.8, 2.8, 4.8, 1.4],\n",
      "       [6.7, 3. , 5. , 1.7],\n",
      "       [6. , 2.9, 4.5, 1.5],\n",
      "       [5.7, 2.6, 3.5, 1. ],\n",
      "       [5.5, 2.4, 3.8, 1.1],\n",
      "       [5.5, 2.4, 3.7, 1. ],\n",
      "       [5.8, 2.7, 3.9, 1.2],\n",
      "       [6. , 2.7, 5.1, 1.6],\n",
      "       [5.4, 3. , 4.5, 1.5],\n",
      "       [6. , 3.4, 4.5, 1.6],\n",
      "       [6.7, 3.1, 4.7, 1.5],\n",
      "       [6.3, 2.3, 4.4, 1.3],\n",
      "       [5.6, 3. , 4.1, 1.3],\n",
      "       [5.5, 2.5, 4. , 1.3],\n",
      "       [5.5, 2.6, 4.4, 1.2],\n",
      "       [6.1, 3. , 4.6, 1.4],\n",
      "       [5.8, 2.6, 4. , 1.2],\n",
      "       [5. , 2.3, 3.3, 1. ],\n",
      "       [5.6, 2.7, 4.2, 1.3],\n",
      "       [5.7, 3. , 4.2, 1.2],\n",
      "       [5.7, 2.9, 4.2, 1.3],\n",
      "       [6.2, 2.9, 4.3, 1.3],\n",
      "       [5.1, 2.5, 3. , 1.1],\n",
      "       [5.7, 2.8, 4.1, 1.3],\n",
      "       [6.3, 3.3, 6. , 2.5],\n",
      "       [5.8, 2.7, 5.1, 1.9],\n",
      "       [7.1, 3. , 5.9, 2.1],\n",
      "       [6.3, 2.9, 5.6, 1.8],\n",
      "       [6.5, 3. , 5.8, 2.2],\n",
      "       [7.6, 3. , 6.6, 2.1],\n",
      "       [4.9, 2.5, 4.5, 1.7],\n",
      "       [7.3, 2.9, 6.3, 1.8],\n",
      "       [6.7, 2.5, 5.8, 1.8],\n",
      "       [7.2, 3.6, 6.1, 2.5],\n",
      "       [6.5, 3.2, 5.1, 2. ],\n",
      "       [6.4, 2.7, 5.3, 1.9],\n",
      "       [6.8, 3. , 5.5, 2.1],\n",
      "       [5.7, 2.5, 5. , 2. ],\n",
      "       [5.8, 2.8, 5.1, 2.4],\n",
      "       [6.4, 3.2, 5.3, 2.3],\n",
      "       [6.5, 3. , 5.5, 1.8],\n",
      "       [7.7, 3.8, 6.7, 2.2],\n",
      "       [7.7, 2.6, 6.9, 2.3],\n",
      "       [6. , 2.2, 5. , 1.5],\n",
      "       [6.9, 3.2, 5.7, 2.3],\n",
      "       [5.6, 2.8, 4.9, 2. ],\n",
      "       [7.7, 2.8, 6.7, 2. ],\n",
      "       [6.3, 2.7, 4.9, 1.8],\n",
      "       [6.7, 3.3, 5.7, 2.1],\n",
      "       [7.2, 3.2, 6. , 1.8],\n",
      "       [6.2, 2.8, 4.8, 1.8],\n",
      "       [6.1, 3. , 4.9, 1.8],\n",
      "       [6.4, 2.8, 5.6, 2.1],\n",
      "       [7.2, 3. , 5.8, 1.6],\n",
      "       [7.4, 2.8, 6.1, 1.9],\n",
      "       [7.9, 3.8, 6.4, 2. ],\n",
      "       [6.4, 2.8, 5.6, 2.2],\n",
      "       [6.3, 2.8, 5.1, 1.5],\n",
      "       [6.1, 2.6, 5.6, 1.4],\n",
      "       [7.7, 3. , 6.1, 2.3],\n",
      "       [6.3, 3.4, 5.6, 2.4],\n",
      "       [6.4, 3.1, 5.5, 1.8],\n",
      "       [6. , 3. , 4.8, 1.8],\n",
      "       [6.9, 3.1, 5.4, 2.1],\n",
      "       [6.7, 3.1, 5.6, 2.4],\n",
      "       [6.9, 3.1, 5.1, 2.3],\n",
      "       [5.8, 2.7, 5.1, 1.9],\n",
      "       [6.8, 3.2, 5.9, 2.3],\n",
      "       [6.7, 3.3, 5.7, 2.5],\n",
      "       [6.7, 3. , 5.2, 2.3],\n",
      "       [6.3, 2.5, 5. , 1.9],\n",
      "       [6.5, 3. , 5.2, 2. ],\n",
      "       [6.2, 3.4, 5.4, 2.3],\n",
      "       [5.9, 3. , 5.1, 1.8]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'frame': None, 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'), 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...', 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], 'filename': 'iris.csv', 'data_module': 'sklearn.datasets.data'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length  sepal width  petal length  petal width  label\n",
       "0             5.1          3.5           1.4          0.2      0\n",
       "1             4.9          3.0           1.4          0.2      0\n",
       "2             4.7          3.2           1.3          0.2      0\n",
       "3             4.6          3.1           1.5          0.2      0\n",
       "4             5.0          3.6           1.4          0.2      0\n",
       "..            ...          ...           ...          ...    ...\n",
       "145           6.7          3.0           5.2          2.3      2\n",
       "146           6.3          2.5           5.0          1.9      2\n",
       "147           6.5          3.0           5.2          2.0      2\n",
       "148           6.2          3.4           5.4          2.3      2\n",
       "149           5.9          3.0           5.1          1.8      2\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['label'] = iris.target\n",
    "df.columns = [\n",
    "        'sepal length', 'sepal width', 'petal length', 'petal width', 'label'\n",
    "    ]\n",
    "print(iris)\n",
    "#df.head()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(criterion='entropy')\n",
    "#clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "#使用plot_tree把决策树进行可视化\n",
    "tree.plot_tree(clf)\n",
    "#显示图像\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_pic = export_graphviz(clf, out_file=\"mytree1.pdf\")\n",
    "with open('mytree1.pdf') as f:\n",
    "    dot_graph = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.50.0 (0)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"527pt\" height=\"373pt\"\n",
       " viewBox=\"0.00 0.00 527.00 373.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 369)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-369 523,-369 523,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"346,-365 236,-365 236,-297 346,-297 346,-365\"/>\n",
       "<text text-anchor=\"middle\" x=\"291\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">x[0] &lt;= 5.45</text>\n",
       "<text text-anchor=\"middle\" x=\"291\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.0</text>\n",
       "<text text-anchor=\"middle\" x=\"291\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 70</text>\n",
       "<text text-anchor=\"middle\" x=\"291\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [35, 35]</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"282.5,-261 171.5,-261 171.5,-193 282.5,-193 282.5,-261\"/>\n",
       "<text text-anchor=\"middle\" x=\"227\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">x[1] &lt;= 3.05</text>\n",
       "<text text-anchor=\"middle\" x=\"227\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.581</text>\n",
       "<text text-anchor=\"middle\" x=\"227\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 36</text>\n",
       "<text text-anchor=\"middle\" x=\"227\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [31, 5]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M270.22,-296.88C264.8,-288.24 258.89,-278.82 253.22,-269.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"256.17,-267.91 247.89,-261.3 250.24,-271.63 256.17,-267.91\"/>\n",
       "<text text-anchor=\"middle\" x=\"242.32\" y=\"-281.97\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"411.5,-261 300.5,-261 300.5,-193 411.5,-193 411.5,-261\"/>\n",
       "<text text-anchor=\"middle\" x=\"356\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">x[1] &lt;= 3.45</text>\n",
       "<text text-anchor=\"middle\" x=\"356\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.523</text>\n",
       "<text text-anchor=\"middle\" x=\"356\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 34</text>\n",
       "<text text-anchor=\"middle\" x=\"356\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 30]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>0&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M312.1,-296.88C317.61,-288.24 323.62,-278.82 329.37,-269.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"332.36,-271.61 334.78,-261.3 326.45,-267.85 332.36,-271.61\"/>\n",
       "<text text-anchor=\"middle\" x=\"340.19\" y=\"-282.01\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"160.5,-157 49.5,-157 49.5,-89 160.5,-89 160.5,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"105\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">x[0] &lt;= 4.85</text>\n",
       "<text text-anchor=\"middle\" x=\"105\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.991</text>\n",
       "<text text-anchor=\"middle\" x=\"105\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n",
       "<text text-anchor=\"middle\" x=\"105\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 5]</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M187.39,-192.88C176.31,-183.62 164.15,-173.45 152.66,-163.85\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"154.75,-161.03 144.83,-157.3 150.26,-166.4 154.75,-161.03\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"281,-149.5 179,-149.5 179,-96.5 281,-96.5 281,-149.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"230\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"230\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 27</text>\n",
       "<text text-anchor=\"middle\" x=\"230\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [27, 0]</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>1&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M227.97,-192.88C228.29,-182.22 228.64,-170.35 228.96,-159.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"232.45,-159.62 229.25,-149.52 225.46,-159.41 232.45,-159.62\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"96,-53 0,-53 0,0 96,0 96,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"48\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"48\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n",
       "<text text-anchor=\"middle\" x=\"48\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 0]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M85.06,-88.95C79.77,-80.17 74.03,-70.66 68.7,-61.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"71.69,-59.99 63.52,-53.24 65.69,-63.61 71.69,-59.99\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"210,-53 114,-53 114,0 210,0 210,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"162\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"162\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n",
       "<text text-anchor=\"middle\" x=\"162\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 5]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M124.94,-88.95C130.23,-80.17 135.97,-70.66 141.3,-61.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"144.31,-63.61 146.48,-53.24 138.31,-59.99 144.31,-63.61\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"405,-149.5 303,-149.5 303,-96.5 405,-96.5 405,-149.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"354\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"354\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 30</text>\n",
       "<text text-anchor=\"middle\" x=\"354\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 30]</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>6&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M355.35,-192.88C355.14,-182.22 354.91,-170.35 354.7,-159.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"358.2,-159.45 354.5,-149.52 351.2,-159.59 358.2,-159.45\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"519,-149.5 423,-149.5 423,-96.5 519,-96.5 519,-149.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"471\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"471\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n",
       "<text text-anchor=\"middle\" x=\"471\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 0]</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>6&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M393.34,-192.88C406.6,-181.12 421.51,-167.89 434.69,-156.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"437.07,-158.77 442.23,-149.52 432.42,-153.54 437.07,-158.77\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x1e711cabfd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第5章决策树-习题\n",
    "\n",
    "### 习题5.1\n",
    "根据表5.1所给的训练数据集，利用信息增益比（C4.5算法）生成决策树。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**  \n",
    "\n",
    "表5.1 贷款申请样本数据表  \n",
    "\n",
    "ID | 年龄 | 有工作 | 有自己的房子 | 信贷情况 | 类别\n",
    ":-: | :-: | :-: | :-: | :-: | :-: \n",
    "1 | 青年 | 否 | 否 | 一般 | 否\n",
    "2 | 青年 | 否 | 否 | 好 | 否\n",
    "3 | 青年 | 是 | 否 | 好 | 是\n",
    "4 | 青年 | 是 | 是 | 一般 | 是\n",
    "5 | 青年 | 否 | 否 | 一般 | 否\n",
    "6 | 中年 | 否 | 否 | 一般 | 否\n",
    "7 | 中年 | 否 | 否 | 好 | 否\n",
    "8 | 中年 | 是 | 是 | 好 | 是\n",
    "9 | 中年 | 否 | 是 | 非常好 | 是\n",
    "10 | 中年 | 否 | 是 | 非常好 | 是\n",
    "11 | 老年 | 否 | 是 | 非常好 | 是\n",
    "12 | 老年 | 否 | 是 | 好 | 是\n",
    "13 | 老年 | 是 | 否 | 好 | 是\n",
    "14 | 老年 | 是 | 否 | 非常好 | 是\n",
    "15 | 老年 | 否 | 否 | 一般 | 否"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"277pt\" height=\"314pt\"\r\n",
       " viewBox=\"0.00 0.00 277.00 314.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 310)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-310 273,-310 273,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<path fill=\"#bddef6\" stroke=\"black\" d=\"M210,-306C210,-306 115,-306 115,-306 109,-306 103,-300 103,-294 103,-294 103,-235 103,-235 103,-229 109,-223 115,-223 115,-223 210,-223 210,-223 216,-223 222,-229 222,-235 222,-235 222,-294 222,-294 222,-300 216,-306 210,-306\"/>\r\n",
       "<text text-anchor=\"start\" x=\"111\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">有自己的房子 ≤ 3.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"129\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.48</text>\r\n",
       "<text text-anchor=\"start\" x=\"119\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 15</text>\r\n",
       "<text text-anchor=\"start\" x=\"122\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 9]</text>\r\n",
       "<text text-anchor=\"start\" x=\"133.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 1</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<path fill=\"#f2c09c\" stroke=\"black\" d=\"M142,-187C142,-187 69,-187 69,-187 63,-187 57,-181 57,-175 57,-175 57,-116 57,-116 57,-110 63,-104 69,-104 69,-104 142,-104 142,-104 148,-104 154,-110 154,-116 154,-116 154,-175 154,-175 154,-181 148,-187 142,-187\"/>\r\n",
       "<text text-anchor=\"start\" x=\"70.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">有工作 ≤ 3.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"68\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\r\n",
       "<text text-anchor=\"start\" x=\"66\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\r\n",
       "<text text-anchor=\"start\" x=\"65\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 3]</text>\r\n",
       "<text text-anchor=\"start\" x=\"76.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M142.724,-222.907C138.524,-214.286 134.044,-205.09 129.701,-196.175\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"132.767,-194.478 125.241,-187.021 126.474,-197.544 132.767,-194.478\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"117.091\" y=\"-206.955\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M257,-179.5C257,-179.5 184,-179.5 184,-179.5 178,-179.5 172,-173.5 172,-167.5 172,-167.5 172,-123.5 172,-123.5 172,-117.5 178,-111.5 184,-111.5 184,-111.5 257,-111.5 257,-111.5 263,-111.5 269,-117.5 269,-123.5 269,-123.5 269,-167.5 269,-167.5 269,-173.5 263,-179.5 257,-179.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"191.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"181\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\r\n",
       "<text text-anchor=\"start\" x=\"180\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 6]</text>\r\n",
       "<text text-anchor=\"start\" x=\"191.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 1</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>0&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M182.623,-222.907C188.093,-211.873 194.029,-199.898 199.544,-188.773\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"202.753,-190.181 204.058,-179.667 196.481,-187.072 202.753,-190.181\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"212.045\" y=\"-199.657\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M85,-68C85,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,-0 12,-0 12,-0 85,-0 85,-0 91,-0 97,-6 97,-12 97,-12 97,-56 97,-56 97,-62 91,-68 85,-68\"/>\r\n",
       "<text text-anchor=\"start\" x=\"19.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"9\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\r\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 0]</text>\r\n",
       "<text text-anchor=\"start\" x=\"19.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M84.2753,-103.726C79.7649,-95.0615 74.9939,-85.8962 70.4568,-77.1802\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"73.556,-75.5537 65.834,-68.2996 67.3469,-78.7859 73.556,-75.5537\"/>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M200,-68C200,-68 127,-68 127,-68 121,-68 115,-62 115,-56 115,-56 115,-12 115,-12 115,-6 121,-0 127,-0 127,-0 200,-0 200,-0 206,-0 212,-6 212,-12 212,-12 212,-56 212,-56 212,-62 206,-68 200,-68\"/>\r\n",
       "<text text-anchor=\"start\" x=\"134.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"124\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\r\n",
       "<text text-anchor=\"start\" x=\"123\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 3]</text>\r\n",
       "<text text-anchor=\"start\" x=\"134.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 1</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>1&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127.097,-103.726C131.687,-95.0615 136.541,-85.8962 141.158,-77.1802\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"144.274,-78.7748 145.862,-68.2996 138.088,-75.4982 144.274,-78.7748\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1e1dd2102c8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "\n",
    "features = [\"年龄\", \"有工作\", \"有自己的房子\", \"信贷情况\"]\n",
    "X_train = pd.DataFrame([\n",
    "    [\"青年\", \"否\", \"否\", \"一般\"],\n",
    "    [\"青年\", \"否\", \"否\", \"好\"],\n",
    "    [\"青年\", \"是\", \"否\", \"好\"],\n",
    "    [\"青年\", \"是\", \"是\", \"一般\"],\n",
    "    [\"青年\", \"否\", \"否\", \"一般\"],\n",
    "    [\"中年\", \"否\", \"否\", \"一般\"],\n",
    "    [\"中年\", \"否\", \"否\", \"好\"],\n",
    "    [\"中年\", \"是\", \"是\", \"好\"],\n",
    "    [\"中年\", \"否\", \"是\", \"非常好\"],\n",
    "    [\"中年\", \"否\", \"是\", \"非常好\"],\n",
    "    [\"老年\", \"否\", \"是\", \"非常好\"],\n",
    "    [\"老年\", \"否\", \"是\", \"好\"],\n",
    "    [\"老年\", \"是\", \"否\", \"好\"],\n",
    "    [\"老年\", \"是\", \"否\", \"非常好\"],\n",
    "    [\"老年\", \"否\", \"否\", \"一般\"]\n",
    "])\n",
    "y_train = pd.DataFrame([\"否\", \"否\", \"是\", \"是\", \"否\", \n",
    "                        \"否\", \"否\", \"是\", \"是\", \"是\", \n",
    "                        \"是\", \"是\", \"是\", \"是\", \"否\"])\n",
    "# 数据预处理\n",
    "le_x = preprocessing.LabelEncoder()\n",
    "le_x.fit(np.unique(X_train))\n",
    "X_train = X_train.apply(le_x.transform)\n",
    "le_y = preprocessing.LabelEncoder()\n",
    "le_y.fit(np.unique(y_train))\n",
    "y_train = y_train.apply(le_y.transform)\n",
    "# 调用sklearn.DT建立训练模型\n",
    "model_tree = DecisionTreeClassifier()\n",
    "model_tree.fit(X_train, y_train)\n",
    "\n",
    "# 可视化\n",
    "dot_data = tree.export_graphviz(model_tree, out_file=None,\n",
    "                                    feature_names=features,\n",
    "                                    class_names=[str(k) for k in np.unique(y_train)],\n",
    "                                    filled=True, rounded=True,\n",
    "                                    special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题5.2\n",
    "&emsp;&emsp;已知如表5.2所示的训练数据，试用平方误差损失准则生成一个二叉回归树。  \n",
    "表5.2 训练数据表  \n",
    "\n",
    "| $x_i$ | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 |  \n",
    "| - | - | - | - | - | - | - | - | - | - | - |  \n",
    "| $y_i$ | 4.50 | 4.75 | 4.91 | 5.34 | 5.80 | 7.05 | 7.90 | 8.23 | 8.70 | 9.00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**  \n",
    "&emsp;&emsp;决策树的生成就是递归地构建二叉决策树的过程，对回归树用平方误差最小化准则，对分类树用基尼指数（Gini index）最小化准则，进行特征选择，生成二叉树。  \n",
    "> 算法5.5（最小二乘回归树生成算法）  \n",
    "输入：训练数据集$D$  \n",
    "输出：回归树$f(x)$  \n",
    "在训练数据集所在的输入空间中，递归地将每个区域划分为两个子区域并决定每个子区域上的输出值，构建二叉决策树；  \n",
    "(1)选择最优切分变量$j$与切分点$s$，求解$$\\min_{j,s} \\left[ \\min_{c_1} \\sum_{x_i \\in R_1(j,s)} (y_i - c_1)^2 + \\min_{c_2} \\sum_{x_i \\in R_2(j,s)} (y_i - c_2)^2\\right]$$遍历变量$j$，对固定的切分变量$j$扫描切分点$s$，选择使得上式达到最小值的对$(j,s)$  \n",
    "(2)用选定的对$(j,s)$划分区域并决定相应的输出值：$$R_1(j,s)=\\{x|x^{(j)}\\leqslant s\\}, R_2(j,s)=\\{x|x^{(j)} > s\\} \\\\ \n",
    "\\hat{c_m} = \\frac{1}{N_m} \\sum_{x_i \\in R_m(j,s)} y_i, x \\in R_m, m=1,2 $$\n",
    "(3)继续对两个子区域调用步骤(1),(2)，直至满足停止条件  \n",
    "(4)将输入空间划分为$M$个区域$R_1,R_2,\\cdots,R_M$，生成决策树：$$f(x)=\\sum_{m=1}^M \\hat{c_m} I(x \\in R_m)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class LeastSqRTree:\n",
    "    def __init__(self, train_X, y, epsilon):\n",
    "        # 训练集特征值\n",
    "        self.x = train_X\n",
    "        # 类别\n",
    "        self.y = y\n",
    "        # 特征总数\n",
    "        self.feature_count = train_X.shape[1]\n",
    "        # 损失阈值\n",
    "        self.epsilon = epsilon\n",
    "        # 回归树\n",
    "        self.tree = None\n",
    "\n",
    "    def _fit(self, x, y, feature_count, epsilon):\n",
    "        # 选择最优切分点变量j与切分点s\n",
    "        (j, s, minval, c1, c2) = self._divide(x, y, feature_count)\n",
    "        # 初始化树\n",
    "        tree = {\"feature\": j, \"value\": x[s, j], \"left\": None, \"right\": None}\n",
    "        if minval < self.epsilon or len(y[np.where(x[:, j] <= x[s, j])]) <= 1:\n",
    "            tree[\"left\"] = c1\n",
    "        else:\n",
    "            tree[\"left\"] = self._fit(x[np.where(x[:, j] <= x[s, j])],\n",
    "                                     y[np.where(x[:, j] <= x[s, j])],\n",
    "                                     self.feature_count, self.epsilon)\n",
    "        if minval < self.epsilon or len(y[np.where(x[:, j] > s)]) <= 1:\n",
    "            tree[\"right\"] = c2\n",
    "        else:\n",
    "            tree[\"right\"] = self._fit(x[np.where(x[:, j] > x[s, j])],\n",
    "                                      y[np.where(x[:, j] > x[s, j])],\n",
    "                                      self.feature_count, self.epsilon)\n",
    "        return tree\n",
    "\n",
    "    def fit(self):\n",
    "        self.tree = self._fit(self.x, self.y, self.feature_count, self.epsilon)\n",
    "\n",
    "    @staticmethod\n",
    "    def _divide(x, y, feature_count):\n",
    "        # 初始化损失误差\n",
    "        cost = np.zeros((feature_count, len(x)))\n",
    "        # 公式5.21\n",
    "        for i in range(feature_count):\n",
    "            for k in range(len(x)):\n",
    "                # k行i列的特征值\n",
    "                value = x[k, i]\n",
    "                y1 = y[np.where(x[:, i] <= value)]\n",
    "                c1 = np.mean(y1)\n",
    "                y2 = y[np.where(x[:, i] > value)]\n",
    "                c2 = np.mean(y2)\n",
    "                y1[:] = y1[:] - c1\n",
    "                y2[:] = y2[:] - c2\n",
    "                cost[i, k] = np.sum(y1 * y1) + np.sum(y2 * y2)\n",
    "        # 选取最优损失误差点\n",
    "        cost_index = np.where(cost == np.min(cost))\n",
    "        # 选取第几个特征值\n",
    "        j = cost_index[0][0]\n",
    "        # 选取特征值的切分点\n",
    "        s = cost_index[1][0]\n",
    "        # 求两个区域的均值c1,c2\n",
    "        c1 = np.mean(y[np.where(x[:, j] <= x[s, j])])\n",
    "        c2 = np.mean(y[np.where(x[:, j] > x[s, j])])\n",
    "        return j, s, cost[cost_index], c1, c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'feature': 0,\n",
       " 'value': 5,\n",
       " 'left': {'feature': 0, 'value': 3, 'left': 4.72, 'right': 5.57},\n",
       " 'right': {'feature': 0,\n",
       "  'value': 7,\n",
       "  'left': {'feature': 0, 'value': 6, 'left': 7.05, 'right': 7.9},\n",
       "  'right': {'feature': 0, 'value': 8, 'left': 8.23, 'right': 8.85}}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = np.array([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]]).T\n",
    "y = np.array([4.50, 4.75, 4.91, 5.34, 5.80, 7.05, 7.90, 8.23, 8.70, 9.00])\n",
    "\n",
    "model_tree = LeastSqRTree(train_X, y, .2)\n",
    "model_tree.fit()\n",
    "model_tree.tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据上面程序的输出，可得到用平方误差损失准则生成一个二叉回归树：$$f(x)=\\begin{cases}\n",
    "4.72 & x \\le 3\\\\\n",
    "5.57 & 3 < x \\le 5\\\\\n",
    "7.05 & 5 < x \\le 6\\\\\n",
    "7.9 & 6 < x \\le 7 \\\\\n",
    "8.23 & 7 < x \\le 8\\\\\n",
    "8.85 & x > 8\\\\\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题5.3\n",
    "\n",
    "&emsp;&emsp;证明 CART 剪枝算法中，当$\\alpha$确定时，存在唯一的最小子树$T_{\\alpha}$使损失函数$C_{\\alpha}(T)$最小。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**  \n",
    "**第1步：**内部节点是否剪枝只与以该节点为根节点的子树有关。  \n",
    "剪枝过程：  \n",
    "计算子树的损失函数：$$C_{\\alpha}(T)=C(T)+\\alpha$$其中，$\\displaystyle C(T) = \\sum_{t=1}^{|T|}N_t (1 - \\sum_{k=1}^K (\\frac{N_{tk}}{N_t})^2)$，$|T|$是叶结点个数，$K$是类别个数。  \n",
    "有剪枝前子树$T_0$，剪枝后子树$T_1$，满足$C_{\\alpha}(T_1) \\leqslant C_{\\alpha}(T_0)$则进行剪枝。 \n",
    "\n",
    "----\n",
    "\n",
    "**第2步（反证法）：**假设当$\\alpha$确定时，存在两颗子树$T_1,T_2$都使得损失函数$C_{\\alpha}$最小。  \n",
    "第1种情况：假设被剪枝的子树在同一边，易知其中一个子树会由另一个子树剪枝而得到，故不可能存在两个最优子树，原结论得证。  \n",
    "第2种情况：假设被剪枝的子树不在同一边，易知被剪枝掉的子树都可以使损失函数$C_{\\alpha}$最小，故两颗子树都可以继续剪枝，故不可能存在两个最优子树，原结论得证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题5.4\n",
    "\n",
    "&emsp;&emsp;证明 CART 剪枝算法中求出的子树序列$\\{T_0,T_1,\\cdots,T_n\\}$分别是区间$\\alpha \\in [\\alpha_i,\\alpha_{i+1})$的最优子树$T_{\\alpha}$，这里$i=0,1,\\cdots,n,0=\\alpha_0 < \\alpha_1 < \\cdots, \\alpha_n < +\\infty$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**  \n",
    "原结论可以表述为：将$\\alpha$从小增大，$0=\\alpha_0<\\alpha_1<\\cdots<\\alpha_n < +\\infty$，在每个区间$[\\alpha_i,\\alpha_{i+1})$中，子树$T_i$是这个区间里最优的。  \n",
    "**第1步：**易证，当$\\alpha=0$时，整棵树$T_0$是最优的，当$\\alpha \\rightarrow +\\infty$时，根结点组成的单结点树（即$T_n$）是最优的。\n",
    "\n",
    "----\n",
    "\n",
    "**第2步：**  \n",
    "&emsp;&emsp;由于每次剪枝剪的都是某个内部结点的子结点，也就是将某个内部结点的所有子结点回退到这个内部结点里，并将这个内部结点作为叶子结点。因此在计算整体的损失函数时，这个内部结点以外的值都没变，只有这个内部结点的局部损失函数改变了，因此本来需要计算全局的损失函数，但现在只需要计算内部结点剪枝前和剪枝后的损失函数。  \n",
    "从整体树$T_0$开始剪枝，对$T_0$的任意内部结点$t$    \n",
    "剪枝前的状态：有$|T_t|$个叶子结点，预测误差是$C(T_t)$  \n",
    "剪枝后的状态：只有本身一个叶子结点，预测误差是$C(t)$\n",
    "因此剪枝前的以$t$结点为根结点的子树的损失函数是$$C_{\\alpha}(T_t) = C(T_t) + \\alpha|T_t|$$剪枝后的损失函数是$$C_{\\alpha}(t) = C(t) + \\alpha$$易得，一定存在一个$\\alpha$使得$C_{\\alpha}(T_t) = C_{\\alpha}(t)$，这个值为$$\\alpha=\\frac{C(t)-C(T_t)}{|T_t|-1}$$可知，找到$\\alpha$即找到了子结点$t$，即完成了剪枝，得到最优子树$T_1$  \n",
    "根据书中第73页，采用以下公式计算剪枝后整体损失函数减少的程度：$$g(t)=\\frac{C(t)-C(T_t)}{|T_t|-1}$$在$T_0$中剪去$g(t)$最小的$T_t$，将得到的子树作为$T_1$，同时将最小的$g(t)$设为$\\alpha_1$，$T_1$为区间$[\\alpha_1,\\alpha_2)$的最优子树。  \n",
    "依次类推，子树$T_i$是区间$[\\alpha_i,\\alpha_{i+1})$里最优的，原结论得证。\n",
    "\n",
    "----\n",
    "\n",
    "**参考文献：**  \n",
    "1. MrTriste：https://blog.csdn.net/wjc1182511338/article/details/76793164\n",
    "2. http://www.pianshen.com/article/1752163397/\n",
    "\n",
    "----\n",
    "\n",
    "**讨论：**为什么$\\alpha$要取最小的$g(t)$呢？  \n",
    "<br/><center>\n",
    "<img style=\"border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);width: 354px;\" src=\"../images/5-1-min-g(t).png\"><br><div style=\"color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #000;padding: 2px;\">图5.1 最小的$g(t)$</div></center>  \n",
    "&emsp;&emsp;以图中两个点为例，结点1和结点2，$g(t)_2$大于$g(t)_1$，假设在所有结点中$g(t)_1$最小，$g(t)_2$最大，两种选择方法：当选择最大值$g(t)_2$，即结点2进行剪枝，但此时结点1的剪枝前的误差大于剪枝后的误差，即如果不剪枝，误差变大，依次类推，对其它所有的结点的$g(t)$都是如此，从而造成整体的累计误差更大。反之，如果选择最小值$g(t)_1$，即结点1进行剪枝，则其余结点不剪的误差要小于剪枝后的误差，不剪枝为好，且整体的误差最小。从而以最小$g(t)$剪枝获得的子树是该$\\alpha$值下的最优子树。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "参考代码：https://github.com/wzyonggege/statistical-learning-method\n",
    "\n",
    "本文代码更新地址：https://github.com/fengdu78/lihang-code\n",
    "\n",
    "习题解答：https://github.com/datawhalechina/statistical-learning-method-solutions-manual\n",
    "\n",
    "中文注释制作：机器学习初学者公众号：ID:ai-start-com\n",
    "\n",
    "配置环境：python 3.5+\n",
    "\n",
    "代码全部测试通过。\n",
    "![gongzhong](../gongzhong.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
